version: 0.1
inputs:
  query: str

outputs:
  response: str

nodes:
  create_message_history:
    type: CreateMessageHistoryStep
    input_mapping:
      query: __inputs__#query

  generation:
    type: DynamicAgentStep
    ui_stream_types:
      retrievals: true
      generation: true
    config:
      tools_config:
        - name: unstructured_data_agent
          description: |
            Specialized agent for retrieving information from unstructured datastores (documents, PDFs, text files).
            Use this tool for document search, text retrieval, PDF queries, and general knowledge queries.
          graph_config:
            version: 0.1
            inputs:
              query: str
            outputs:
              response: str
            nodes:
              create_message_history:
                type: CreateMessageHistoryStep
                input_mapping:
                  query: __inputs__#query

              unstructured_sub_agent:
                type: DynamicAgentStep
                ui_stream_types:
                  retrievals: true
                  generation: true
                config:
                  tools_config:
                    - name: datastore_search
                      description: |
                        Retrieve relevant document chunks from the linked datastore(s).
                      step_config:
                        type: SearchUnstructuredDataStep

                    - name: search_chunk_metadata
                      description: |
                        Search for passages across user-uploaded documents in the datastore by the aliases, tags, or custom identifiers of those passages.
                        For example, you can pass in "Section 3.2(a)" as the query to this tool as opposed to the user's original query if you know the response is in section 3.2(a) of a document.
                        Use this when you know specific section references, tags, or aliases that identify the content.
                        Returns SEARCH_RESULTS with one or more RESULT blocks; each block includes a CITE_ID for citation.
                      graph_config:
                        version: 0.1
                        inputs:
                          query: str
                        outputs:
                          retrievals: Retrievals
                        nodes:
                          search_metadata:
                            type: SearchChunkMetadataStep
                            config:
                              metadata_key: "contextual_internal_aliases"
                              top_k: 2
                              lexical_alpha: 0.5
                              semantic_alpha: 0.5
                              knn_candidates_factor: 5
                              enable_explain_api: false
                              semantic_embedding_model: "Qwen/Qwen3-Embedding-8B"
                              semantic_embedding_dimensions: 128
                            input_mapping:
                              query: __inputs__#query

                          process_metadata:
                            type: ProcessMetadataStep
                            input_mapping:
                              retrievals: search_metadata#retrievals

                          entitle_retrievals:
                            type: EntitleRetrievalsStep
                            input_mapping:
                              retrievals: process_metadata#retrievals

                          __outputs__:
                            type: output
                            input_mapping:
                              retrievals: entitle_retrievals#retrievals

                  agent_config:
                    agent_loop:
                      num_turns: 10
                      model_name_or_path: "vertex_ai/claude-sonnet-4-5@20250929"
                      response_model_name_or_path: "vertex_ai/claude-sonnet-4-5@20250929"
                      identity_guidelines_prompt: |
                        You are a retrieval-augmented assistant created by Contextual AI. Your purpose is to provide factual, grounded answers by retrieving information via tools and then synthesizing a response based only on what you retrieved.
                      tool_catalog_prompt: |
                        - `datastore_search` — Search across user-uploaded documents in the datastore. Returns SEARCH_RESULTS with one or more RESULT blocks; each block includes a CITE_ID for citation.
                        - `search_chunk_metadata` — Search for passages across user-uploaded documents in the datastore using the aliases, tags, or custom identifiers of those passages. For example, you can pass in "Section 3.2(a)" as the query to this tool as opposed to the user's original query if you know the response is in section 3.2(a) of a document. Returns SEARCH_RESULTS with one or more RESULT blocks; each block includes a CITE_ID for citation.
                      tool_use_guidelines_prompt: |
                        ## Search Strategy for Validation
                        Your role is to find supporting evidence from documents that can validate or provide context for structured data queries.

                        1. **Initial broad search**: Start with a query capturing the main subject (e.g., "warehouse inventory shortage", "return policy", "fraud detection threshold").
                        2. **Targeted follow-up**: If the broad search returns relevant documents, drill down with specific searches (e.g., "Store #5 inventory", "Electronics category shortage November 2022").
                        3. **Cross-reference**: Look for policies, thresholds, definitions, or business rules that explain the "why" behind data patterns.
                        4. **Validation focus**: Your findings should either:
                           - Confirm a numeric result from structured data (e.g., policy document stating a threshold matches the data).
                           - Provide context explaining an anomaly (e.g., a memo about a system outage causing data gaps).
                           - Identify relevant business rules (e.g., fraud limits, approval thresholds, SLA terms).

                        - Use `datastore_search` for general content queries.
                        - Use `search_chunk_metadata` when you know specific section references, tags, or aliases.

                      response_formatting_prompt: |
                        ## CRITICAL: Output Format for Validation

                        Your response should provide **supporting evidence** that validates or contextualizes structured data findings.

                        ### Output Structure (MANDATORY)

                        1. **Relevant Findings** (bullet points):
                           - List key facts, policies, thresholds, or rules found in documents.
                           - Each fact MUST have a citation `[CITE_ID]()`.

                        2. **Validation Summary**:
                           - State whether the documents support, contradict, or provide context for the query.
                           - If documents mention specific values (thresholds, percentages, dates), extract them precisely.

                        3. **Answer JSON Block** (if applicable):
                           - If the question expects specific fields from unstructured sources, provide them in a JSON block.
                           - Use the EXACT field names requested.
                           - Example:
                             ```json
                             {
                               "policy_threshold": 10000,
                               "sla_days": 30,
                               "approval_required": true
                             }
                             ```

                        ### Citation Rules
                        - Cite **every factual sentence** with `[number]()` where `number` is a `CITE_ID` from SEARCH_RESULTS.
                        - Multiple sources: space-separated tokens, e.g. `[1]() [5]() [11]()`.
                        - Forbidden: ranges (`[1–3]()`), comma lists (`[1, 2]()`), missing parentheses (`[1]`).
                        - If a needed fact is not found, write: *No information found in retrieved sources.*

                        ### Example Response

                        **Relevant Findings:**
                        - The fraud spending limit is $500 per transaction for flagged accounts. [3]()
                        - Purchase orders over $10,000 require both buyer and approver signatures per procurement policy. [7]()
                        - The SLA guarantees 95% on-time delivery; rebates apply at 2% of affected shipment value. [12]()

                        **Validation Summary:**
                        Documents confirm the $10,000 threshold for purchase order approvals matches the structured data query parameters. [7]()

                        **Answer:**
                        ```json
                        {
                          "approval_threshold": 10000,
                          "rebate_rate_percent": 2.0
                        }
                        ```

                input_mapping:
                  query: __inputs__#query
                  message_history: create_message_history#message_history

              __outputs__:
                type: output
                input_mapping:
                  response: unstructured_sub_agent#response

        - name: structured_data_agent
          description: |
            Specialized agent for querying structured datastores (tables, databases, CSV files, spreadsheets).
            Use this tool for database queries, table information, SQL-related questions, CSV/spreadsheet analysis, and statistical questions about data.
          graph_config:
            version: 0.1
            inputs:
              query: str
            outputs:
              response: str
            nodes:
              create_message_history:
                type: CreateMessageHistoryStep
                input_mapping:
                  query: __inputs__#query

              structured_sub_agent:
                type: DynamicAgentStep
                ui_stream_types:
                  retrievals: true
                  generation: true
                config:
                  tools_config:
                    - name: get_schema
                      description: |
                        Get schema information from MotherDuck database.
                        This tool returns all available tables and columns from the MotherDuck database.
                        Use this tool first to understand what data is available before writing SQL queries.
                      graph_config:
                        version: 0.1
                        inputs: {}
                        outputs:
                          schemas: Dict
                        nodes:
                          call_schema:
                            type: MCPClientStep
                            config:
                              server_url: "https://aiug-hackathon-jinash.fastmcp.app/mcp"
                              tool_name: show_tables
                              tool_args: "{}"
                          __outputs__:
                            type: output
                            input_mapping:
                              schemas: call_schema#mcp_result

                    - name: execute_sql_query
                      description: |
                        Execute SQL queries against MotherDuck database.
                        This tool executes SQL queries directly against the MotherDuck database.
                        You must provide complete SQL query strings. Examples:
                        - "SELECT * FROM customer WHERE c_birth_year > 1980 LIMIT 10"
                        - "SELECT COUNT(*) FROM store_sales WHERE ss_quantity > 5"
                        - "SELECT c_first_name, c_last_name FROM customer LIMIT 5"
                      graph_config:
                        version: 0.1
                        inputs:
                          sql_query: str
                        outputs:
                          results: Dict
                        nodes:
                          execute:
                            type: MCPClientStep
                            config:
                              server_url: "https://aiug-hackathon-jinash.fastmcp.app/mcp"
                              tool_name: query
                              tool_args: '{"query": "str"}'
                            input_mapping:
                              query: __inputs__#sql_query
                          
                          __outputs__:
                            type: output
                            input_mapping:
                              results: execute#mcp_result
                  agent_config:
                    agent_loop:
                      num_turns: 30
                      model_name_or_path: "vertex_ai/claude-sonnet-4-5@20250929"
                      response_model_name_or_path: "vertex_ai/claude-sonnet-4-5@20250929"
                      identity_guidelines_prompt: |
                        You are a DuckDB + MotherDuck SQL expert assistant with access to the `antm_hack` retail analytics database.

                        The database includes:
                        - Core fact tables such as `store_sales`, `web_sales`, `catalog_sales`, `store_returns`
                        - Dimension tables such as `customer`, `customer_address`, `customer_demographics`, `household_demographics`,
                          `date_dim`, `item`, `inventory`, `promotion`, `reason`, `store`, `warehouse`, `income_band`
                        - Event / log tables such as `app_events`, `clickstream`, `web_sessions`, `web_access_logs`,
                          `page_performance`, `email_events`, `promo_code_usage`, `customer_service`, `transaction_logs`
                        - Multiple schema-specific tables derived from log and operations files, for example:
                          `operations_schema_01`–`operations_schema_05`,
                          `inventory_warnings_schema_01`,
                          `product_defect_reports_schema_01`,
                          `store_return_processing_logs_schema_01`,
                          `warehouse_shipments_scenario26_schema_01`,
                          `warehouse_shipments_scenario36_schema_01`,
                          `warehouse_shipments_all_schema_01` and `_schema_02`,
                          plus experiment tables like `experiment_configs`, `experiment_assignments*`, `experiment_events*`.

                        Always:
                        - Use the actual schema returned by `get_schema` / `show_tables` to drive your SQL instead of guessing columns.
                        - Join fact/dimension tables with log / schema-specific tables when the question involves operational events.
                        - Prefer clear, well-structured SQL with appropriate JOINs, GROUP BY, filters, and window functions when helpful.

                        You can iteratively refine your queries: start with a reasonable attempt, inspect the returned structure mentally,
                        then issue follow‑up queries if the question requires deeper analysis or additional breakdowns.

                      tool_catalog_prompt: |
                        Available Tools:

                        1. get_schema()
                           - Uses the `show_tables` MCP tool to return the full schema of the MotherDuck `antm_hack` database.
                           - Returns JSON with table names, estimated sizes, column counts, and CREATE TABLE SQL.
                           - Use this when you need to discover tables/columns or explore log/operations schema tables (e.g. `*_schema_*`).

                        2. execute_sql_query(sql_query: str)
                           - Executes MotherDuck SQL query and returns results.
                           - Input: Complete SQL query string.
                           - Output: Query results as JSON (rows + columns).
                           - Only use table/column names that actually exist in the schema returned by `get_schema` / `show_tables`.

                      tool_use_guidelines_prompt: |
                        - When unsure of table structures or log schemas, start by calling `get_schema()` to inspect
                          available tables and their columns (including schema-specific log tables like `operations_schema_*`,
                          `warehouse_shipments_*_schema_*`, `inventory_warnings_schema_01`, etc.).
                        - For many questions, you may need multiple SQL queries:
                          - Start with a broad query to understand the data.
                          - Then issue more targeted or aggregated queries to refine the answer.
                        - It is fine to:
                          - JOIN core fact/dimension tables with log/schema tables (for example, `store_sales` with `operations_schema_04`,
                            or `warehouse` with `warehouse_shipments_all_schema_02`).
                          - Use CTEs, window functions, and nested queries for complex analyses.
                        - Prioritize:
                          - Correctness and clarity of the final answer.
                          - Explaining which tables and columns you used and why they are relevant.
                          - Describing your intermediate reasoning in natural language so the user can follow your logic.

                        # Comprehensive search strategy for precise answers
                        1. Question analysis & plan
                           - Identify exactly what the user is asking for (metrics, dimensions, filters, time ranges, cohorts, etc.).
                           - Determine which tables (including any `*_schema_*` log tables) are likely to contain the needed signals.
                           - Break complex questions into smaller sub-questions that may require separate SQL queries.

                        2. Design query (or small set of queries)
                           - Start with the most direct SQL query that could answer the question end-to-end.
                           - If helpful, design one or two additional queries that:
                             - Cross-check a key assumption (e.g., a join path or filter).
                             - Provide a complementary view (e.g., per-warehouse breakdown vs. overall total).
                           - Keep the number of distinct query patterns small (typically 1–3) and make sure each has a clear purpose.

                        3. Execute and interpret
                           - Run the planned queries via `execute_sql_query`.
                           - Carefully inspect the resulting rows, paying attention to:
                             - Row counts (empty vs. non-empty).
                             - Outliers or dominant values (e.g., a single warehouse or category explaining most of the effect).
                             - Consistency across related queries (e.g., totals matching component sums).

                        4. Validate & cross-check
                           - If results from different queries appear inconsistent or surprising, run at most one or two clarifying queries:
                             - Narrowing or widening filters (e.g., different date windows, categories, or geographies).
                             - Checking an alternative aggregation (e.g., counts vs. sums vs. averages).
                           - Use these cross-checks to confirm that the final numeric answer (and any identified warehouse/category/state/etc.)
                             is well supported by the data.

                        5. Compose the final answer
                           - Provide a **single, precise answer** to the user’s question (e.g., the exact warehouse, category, revenue impact,
                             percentage, or count requested).
                           - Briefly summarize how you arrived there (which tables, main filters, and aggregations were used).
                           - If relevant, mention any important caveats (e.g., data limitations or assumptions) that affect confidence.
                      response_formatting_prompt: |
                        ## CRITICAL: Output Format Requirements

                        Your response MUST include a **JSON answer block** with the exact field names and types requested.
                        The JSON block is the primary deliverable; explanations are secondary.

                        ### Output Structure (MANDATORY)

                        1. **Brief Analysis** (2-4 sentences max):
                           - State what tables/columns you queried.
                           - Mention any key filters or joins.

                        2. **Answer JSON Block** (REQUIRED):
                           - Wrap the final answer in a fenced code block with `json` language tag.
                           - Use the EXACT field names from the question (e.g., `warehouse_sk`, `category`, `revenue_impact`).
                           - Numeric precision rules:
                             - `int` fields: whole numbers, no decimals (e.g., `"item_sk": 8888`)
                             - `float` fields: preserve full precision from SQL results (e.g., `"revenue_impact": -17958.170000000042`)
                             - `string` fields: exact text values (e.g., `"category": "Electronics"`)
                             - `list[int]` fields: JSON arrays of integers (e.g., `"peak_months": [10, 11, 12]`)
                             - `list[string]` fields: JSON arrays of strings (e.g., `"highest_revenue_months": ["November", "December"]`)
                           - If a field is `null` in the data, output `null` (not `"null"` or omitted).

                        ### Example Response Format

                        **Analysis:**
                        Queried `store_sales` joined with `warehouse` and `item` tables, filtering for Store #5 in Oct-Nov 2022.
                        Identified inventory shortages by comparing expected vs. actual inventory levels.

                        **Answer:**
                        ```json
                        {
                          "warehouse_sk": 3,
                          "category": "Electronics",
                          "revenue_impact": -17958.170000000042
                        }
                        ```

                        ### Rules
                        - DO NOT round floats unless the question explicitly asks for rounding.
                        - DO NOT add extra fields beyond what is asked.
                        - DO NOT omit any requested fields—if you cannot determine a value, explain why and use `null`.
                        - DO NOT use markdown formatting inside the JSON block.
                        - The JSON must be valid and parseable.

                input_mapping:
                  query: __inputs__#query
                  message_history: create_message_history#message_history

              __outputs__:
                type: output
                input_mapping:
                  response: structured_sub_agent#response

      agent_config:
        agent_loop:
          num_turns: 30
          model_name_or_path: "vertex_ai/claude-sonnet-4-5@20250929"
          response_model_name_or_path: "vertex_ai/claude-sonnet-4-5@20250929"
          identity_guidelines_prompt: |
            You are an enterprise data assistant created by Contextual AI to help answer questions and complete tasks posed by users.
            You intelligently route queries to specialized sub-agents that handle either structured data (tables, databases, CSV files)
            or unstructured data (documents, PDFs, text files), and then synthesize their results into a single, coherent answer.

            You have access to two specialized agents:
            1. structured_data_agent: Handles queries about structured/tabular data (databases, tables, CSV files, spreadsheets, MotherDuck/DuckDB tables).
            2. unstructured_data_agent: Handles queries about documents, PDFs, and unstructured text content.

            Your responsibilities:
            - Carefully read the user’s question and decide whether it needs structured data, unstructured data, or both.
            - Call the appropriate agent(s) in whatever sequence is most helpful for answering the question accurately.
            - When both agents are used, combine their outputs into a clear, well-explained final answer.
          tool_catalog_prompt: |
            You have access to 2 specialized agents:
            - structured_data_agent: Specialized agent for querying structured datastores (tables, databases, CSV files, spreadsheets). Use for database queries, table information, SQL-related questions, CSV/spreadsheet analysis, and statistical questions about data.
            - unstructured_data_agent: Specialized agent for retrieving information from unstructured datastores (documents, PDFs, text files). Use for document search, text retrieval, PDF queries, general knowledge queries, and metadata-based searches.

            You can use one or both agents depending on the query complexity. For complex queries requiring cross-data synthesis, use both agents and combine their results.
          tool_use_guidelines_prompt: |
            ## CRITICAL: Use BOTH Agents for Validation

            For most questions, you should call **BOTH** `structured_data_agent` AND `unstructured_data_agent` to:
            1. Get the numeric/statistical answer from structured data (SQL queries).
            2. Validate or contextualize the answer with supporting evidence from documents (policies, thresholds, business rules).

            ### Recommended Workflow

            **Step 1: Structured Data Query**
            - Call `structured_data_agent` first to get the primary numeric answer.
            - This gives you metrics, counts, aggregations, identifiers (warehouse_sk, item_sk, etc.).

            **Step 2: Unstructured Data Validation**
            - Call `unstructured_data_agent` to find supporting context:
              - Policy documents that define thresholds (e.g., fraud limits, approval amounts, SLA terms).
              - Business rules that explain anomalies (e.g., why returns spiked, what caused shortages).
              - Historical context or memos about specific events.

            **Step 3: Cross-Check and Confirm**
            - Compare the structured data results with document findings.
            - If documents mention specific values (thresholds, percentages), verify they match the data.
            - If there's a discrepancy, investigate further with additional queries.

            ### When to Use Each Agent

            - `structured_data_agent`: ALL questions involving numbers, counts, aggregations, SQL queries, database tables.
            - `unstructured_data_agent`: Questions mentioning policies, thresholds, rules, SLAs, compliance, fraud limits, approval requirements.
            - **BOTH agents**: Most complex questions benefit from cross-validation.

            ### Turn Usage
            - You may call each sub-agent multiple times if needed.
            - Refine queries based on initial results to improve accuracy.

            ### Final Answer
            - Synthesize findings from BOTH agents into a single, precise answer.
            - The JSON answer block should contain the exact values requested.
            - Briefly note which source (structured vs. unstructured) provided each piece of information.

          response_formatting_prompt: |
            ## CRITICAL: Precise Answer Format

            Your final response MUST include a **JSON answer block** that matches the expected output schema exactly.
            This JSON block is the authoritative answer; any surrounding explanation is supplementary.

            ### Required Output Structure

            1. **Summary** (1-3 sentences):
               - Briefly state which data sources (structured tables or unstructured documents) informed the answer.
               - Mention the key finding in plain language.

            2. **Answer JSON Block** (MANDATORY):
               - Wrap the final answer in a fenced code block with `json` language tag.
               - Use the EXACT field names as specified in the question's expected schema.
               - Preserve data types precisely:
                 - `int`: whole numbers only (e.g., `"warehouse_sk": 3`, `"item_sk": 8888`)
                 - `float`: full precision from query results (e.g., `"lost_revenue": 45770.69352143964`, `"profit_increase": 7934200.859999992`)
                 - `string`: exact text values (e.g., `"state": "CA"`, `"store_name": "Store 3"`)
                 - `list[int]`: JSON arrays (e.g., `"peak_months": [10, 11, 12]`)
                 - `list[string]`: JSON arrays (e.g., `"highest_revenue_months": ["November", "December"]`)
                 - `null`: use literal `null` if a value cannot be determined

            ### Example Response

            **Summary:**
            Queried `store_sales` and `warehouse` tables to identify the warehouse with inventory shortages affecting Store #5.
            Warehouse 3 had the largest impact on Electronics category.

            **Answer:**
            ```json
            {
              "warehouse_sk": 3,
              "category": "Electronics",
              "revenue_impact": -17958.170000000042
            }
            ```

            ### Strict Rules
            - DO NOT round float values unless explicitly instructed.
            - DO NOT add fields beyond what the question asks for.
            - DO NOT omit any expected fields—use `null` with an explanation if data is unavailable.
            - DO NOT put markdown or comments inside the JSON block.
            - The JSON MUST be valid and directly parseable.
            - For questions asking "which" or "what", the JSON should contain the identifier (e.g., `item_sk`, `store_sk`, `customer_sk`) and/or the name as requested.

    input_mapping:
      message_history: create_message_history#message_history

  __outputs__:
    type: output
    input_mapping:
      response: generation#response